import os
from PIL import Image
from torch.utils.data import Dataset
import torchvision.transforms as transforms
import glob
import tqdm
import csv
from typing import Dict, List, Iterable
import torch
import numpy as np

class GOOSE_SemanticDataset(Dataset):
    """
    PyTorch Dataset Module for semantic segmentation tasks with GOOSE dataset.

    Args:
        dataset_dict (List[Dict]): List of dictionaries with images information generated by goose_create_dataDict.
        crop (bool): Whether to make a square crop of the images or not.
        resize_size (Iterable[int]): Resize size of the images [height, width].
    """

    def __init__(self, dataset_dict: List[Dict], crop: bool = True, resize_size: Iterable[int] = None):
        self.dataset_dict = dataset_dict
        self.transforms = transforms.Compose([
            transforms.ToTensor(),
        ])
        self.resize_size = resize_size
        self.crop = crop

    def preprocess(self, image):
        if image is None:
            return None
        if self.crop:
            # Center square crop
            s = min(image.width, image.height)
            image = transforms.CenterCrop((s, s))(image)
        if self.resize_size is not None:
            # Resize
            image = image.resize(self.resize_size, resample=Image.NEAREST)
        return image

    def __getitem__(self, idx):
        """
        Get item by index.

        Args:
            idx (int): Index.

        Returns:
            (image_tensor, label_tensor)
        """
        image = Image.open(self.dataset_dict[idx]['img_path']).convert('RGB')
        label = Image.open(self.dataset_dict[idx]['semantic_path']).convert('L')

        image = self.preprocess(image)
        label = self.preprocess(label)

        image_tensor = self.transforms(image)
        label_tensor = torch.from_numpy(np.array(label)).long()

        return image_tensor, label_tensor

    def __len__(self):
        return len(self.dataset_dict)


def __check_labels(img_path: str, lbl_path: str) -> bool:
    """
    Check if a valid set of label files exists for an image.
    """
    name = os.path.basename(img_path)
    name, ext = name.split('.')
    name = '_'.join(name.split('_')[:-2])

    names = []
    for l in ['color', 'instanceids', 'labelids']:
        lbl_name = name + '_' + l + '.' + ext
        if not os.path.exists(os.path.join(lbl_path, lbl_name)):
            return False, None
        names.append(lbl_name)
    return True, names


def __goose_datadict_folder(img_path: str, lbl_path: str):
    """
    Create a data dictionary with image paths and corresponding label paths.

    Args:
        img_path (str): Path to images folder.
        lbl_path (str): Path to labels folder.

    Returns:
        List of dictionaries with keys: img_path, semantic_path, instance_path, color_path
    """
    subfolders = glob.glob(os.path.join(img_path, '*/'), recursive=False)
    subfolders = [f.split('/')[-2] for f in subfolders]

    datadict = []

    for s in tqdm.tqdm(subfolders):
        imgs_p = os.path.join(img_path, s)
        lbls_p = os.path.join(lbl_path, s)
        imgs = glob.glob(os.path.join(imgs_p, '*.png'))
        for img in imgs:
            valid, lbl_names = __check_labels(img, lbls_p)
            if not valid:
                continue
            datadict.append({
                'img_path': img,
                'semantic_path': os.path.join(lbls_p, lbl_names[2]),
                'instance_path': os.path.join(lbls_p, lbl_names[1]),
                'color_path': os.path.join(lbls_p, lbl_names[0]),
            })

    return datadict


def goose_create_dataDict(src_path: str, mapping_csv_name: str = None) -> Dict:
    """
    Create train, validation, and test data dictionaries for GOOSE dataset.

    Args:
        src_path (str): Path to the top-level dataset directory (should contain 'train', 'val', 'test').
        mapping_csv_name (str, optional): Name of the mapping CSV file. Default is None.

    Returns:
        Tuple: (test_dict, train_dict, val_dict, mapping)
    """
    mapping = None
    if mapping_csv_name is not None:
        mapping_path = os.path.join(src_path, 'train', mapping_csv_name)
        if os.path.exists(mapping_path):
            mapping = []
            with open(mapping_path, newline='') as f:
                reader = csv.DictReader(f)
                for r in reader:
                    mapping.append(r)
        else:
            print(f"⚠️ Warning: Mapping CSV '{mapping_csv_name}' not found at {mapping_path}")

    datadicts = []

    for split in ['test', 'train', 'val']:
        print(f"### {split.capitalize()} Data ###")
        split_img_root = os.path.join(src_path, split, 'images', split)
        split_lbl_root = os.path.join(src_path, split, 'labels', split)

        datadicts.append(
            __goose_datadict_folder(
                split_img_root,
                split_lbl_root
            )
        )

    test, train, val = datadicts

    return test, train, val, mapping
